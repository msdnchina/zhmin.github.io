<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="kafka, producer,">










<meta name="description" content="Kafka Producer 原理Kafka为使用者提供了客户端，负责向Kafka中写入消息，由KafkaProducer实现。KafkaProducer为了提高系统的吞吐量，它会先将消息缓存起来，然后以批次为单位的发送。具体原理如下：  KafkaProducer将消息发送给RecordAccumulator缓存。 RecordAccumulator会将消息，以ProducerBatch的格式存">
<meta name="keywords" content="kafka, producer">
<meta property="og:type" content="article">
<meta property="og:title" content="KafkaProducer 原理">
<meta property="og:url" content="https://zhmin.github.io/2019/03/11/kafka-producer/index.html">
<meta property="og:site_name" content="学习笔记">
<meta property="og:description" content="Kafka Producer 原理Kafka为使用者提供了客户端，负责向Kafka中写入消息，由KafkaProducer实现。KafkaProducer为了提高系统的吞吐量，它会先将消息缓存起来，然后以批次为单位的发送。具体原理如下：  KafkaProducer将消息发送给RecordAccumulator缓存。 RecordAccumulator会将消息，以ProducerBatch的格式存">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://zhmin.github.io/2019/03/11/kafka-producer/kafka-producer.svg">
<meta property="og:updated_time" content="2020-09-25T01:58:36.156Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="KafkaProducer 原理">
<meta name="twitter:description" content="Kafka Producer 原理Kafka为使用者提供了客户端，负责向Kafka中写入消息，由KafkaProducer实现。KafkaProducer为了提高系统的吞吐量，它会先将消息缓存起来，然后以批次为单位的发送。具体原理如下：  KafkaProducer将消息发送给RecordAccumulator缓存。 RecordAccumulator会将消息，以ProducerBatch的格式存">
<meta name="twitter:image" content="https://zhmin.github.io/2019/03/11/kafka-producer/kafka-producer.svg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhmin.github.io/2019/03/11/kafka-producer/">





  <title>KafkaProducer 原理 | 学习笔记</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">学习笔记</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhmin.github.io/2019/03/11/kafka-producer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhmin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="学习笔记">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">KafkaProducer 原理</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-11T21:44:15+08:00">
                2019-03-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index">
                    <span itemprop="name">kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/11/kafka-producer/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/11/kafka-producer/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/11/kafka-producer/" class="leancloud_visitors" data-flag-title="KafkaProducer 原理">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Kafka-Producer-原理"><a href="#Kafka-Producer-原理" class="headerlink" title="Kafka Producer 原理"></a>Kafka Producer 原理</h1><p>Kafka为使用者提供了客户端，负责向Kafka中写入消息，由KafkaProducer实现。KafkaProducer为了提高系统的吞吐量，它会先将消息缓存起来，然后以批次为单位的发送。具体原理如下：</p>
<p><img src="/2019/03/11/kafka-producer/kafka-producer.svg" alt="kafka-producer"></p>
<p>KafkaProducer将消息发送给RecordAccumulator缓存。</p>
<p>RecordAccumulator会将消息，以ProducerBatch的格式存储起来。它为每一个分区都生成了一个ProducerBatch的队列。</p>
<p>Sender会从RecordAccumulator拉取消息批次ProducerBatch，然后生成请求，通过NetworkClient发送出去。</p>
<h2 id="消息生成者-KafkaProducer"><a href="#消息生成者-KafkaProducer" class="headerlink" title="消息生成者 KafkaProducer"></a>消息生成者 KafkaProducer</h2><p>KafkaProducer负责将消息序列化，并且确定消息发往哪个节点。它还支持钩子函数，由ProducerInterceptors表示。目前支持发送前的onSend函数，和发送错误后的onSendError函数。</p>
<p>KafkaProducer发送消息有两种方式，一种是不指定callback，一种是指定callback。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducer</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Producer</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 序列化器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ExtendedSerializer&lt;K&gt; keySerializer;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ExtendedSerializer&lt;V&gt; valueSerializer;</span><br><span class="line">    <span class="comment">// 钩子函数集合</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ProducerInterceptors&lt;K, V&gt; interceptors;</span><br><span class="line">    <span class="comment">// 消息缓冲区</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RecordAccumulator accumulator;</span><br><span class="line">    <span class="comment">// 默认的分区器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Partitioner partitioner;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> send(record, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 调用onSend钩子函数</span></span><br><span class="line">        ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors.onSend(record);</span><br><span class="line">        <span class="keyword">return</span> doSend(interceptedRecord, callback);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">        TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 获取该topic partition的元数据</span></span><br><span class="line">            ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">            Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line">            <span class="comment">// 序列化key值</span></span><br><span class="line">            <span class="keyword">byte</span>[] serializedKey;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(...);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 序列化value值</span></span><br><span class="line">            <span class="keyword">byte</span>[] serializedValue;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(...);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 调用partition函数，确认发往哪个节点</span></span><br><span class="line">            <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">            <span class="comment">// 发往消息缓冲区</span></span><br><span class="line">            RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs);            </span><br><span class="line">            <span class="comment">// 如果此时有batch完成，则调用sender的wakeup方法，通知sender，防止它阻塞</span></span><br><span class="line">            <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">                <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> result.future;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 调用onSendError钩子函数</span></span><br><span class="line">            <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面有个比较重要的partition方法，确定消息发往哪个分区。这个算法由分区器Partitioner表示。kafka有个默认的分区器，同时它也支持自定义。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DefaultPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// key为topic名称，value为计数器，初始值为随机分配的。每次添加消息，都会自增</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 获取这个topic的分区数目</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">        <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 如果消息的key值为空，则更新计数器的值</span></span><br><span class="line">            <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line">            <span class="comment">// 获取有效的分区（有效是指该分区的leader副本正常运行）</span></span><br><span class="line">            List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">            <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// 取余数</span></span><br><span class="line">                <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">                <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 简单取余</span></span><br><span class="line">                <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 使用murmur2哈希算法，生成key的哈希值，然后取余 </span></span><br><span class="line">            <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="消息缓冲区-RecordAccumulator"><a href="#消息缓冲区-RecordAccumulator" class="headerlink" title="消息缓冲区 RecordAccumulator"></a>消息缓冲区 RecordAccumulator</h2><p>RecordAccumulator作为消息缓冲区，它为每个topic partition，生成了一个ProducerBatch的队列。ProducerBatch表示消息批次，每个ProducerBatch也都有大小限制，当它的缓存空间存储满了之后，就会新建一个ProducerBatch。</p>
<h3 id="ProducerBatch-原理"><a href="#ProducerBatch-原理" class="headerlink" title="ProducerBatch 原理"></a>ProducerBatch 原理</h3><p>ProducerBatch包含了多条消息，最终可以转换为MemoryRecords的格式，发送给服务端。</p>
<p>ProducerBatch提供了两个重要的方法：</p>
<ul>
<li>tryAppend方法，支持添加消息</li>
<li>records方法，返回MemoryRecords</li>
</ul>
<p>ProducerBatch使用MemoryRecordsBuilder类，负责构建MemoryRecords。MemoryRecords是Kafka中保存消息，常见的一种格式。这里需要说明下，Kafka发送消息，是以batch为单位的，每个batch包含了多条消息。MemoryRecords定义了batch的数据格式。</p>
<p>当Kafka发送一个batch后，会得到响应。这个batch响应又包含了里面每个消息的响应。</p>
<p>batch的响应由ProduceRequestResult类表示</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ProduceRequestResult</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TopicPartition topicPartition;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Long baseOffset = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">long</span> logAppendTime = RecordBatch.NO_TIMESTAMP;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> RuntimeException error;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>单个消息的响应由FutureRecordMetadata类表示， 它在ProduceRequestResult之上生成</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">FutureRecordMetadata</span> <span class="keyword">implements</span> <span class="title">Future</span>&lt;<span class="title">RecordMetadata</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ProduceRequestResult result;   <span class="comment">// batch响应</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> relativeOffset;           <span class="comment">// 此条消息在batch中的位置</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> createTimestamp;          <span class="comment">// 创建时间</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long checksum;                 <span class="comment">// 校检值</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> serializedKeySize;         <span class="comment">// key序列化之后的数据长度</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> serializedValueSize;       <span class="comment">// value序列化之后的数据长度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ProducerBatch在添加消息的时候，就实例化消息的响应。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerBatch</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 保存了回调函数，当ProducerBatch发送完成后，会调用里面每条消息的回调函数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Thunk&gt; thunks = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="comment">// MemoryRecords构造器</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> MemoryRecordsBuilder recordsBuilder;</span><br><span class="line">    <span class="comment">// 包含消息的数目</span></span><br><span class="line">    <span class="keyword">int</span> recordCount;</span><br><span class="line">    <span class="comment">// 表示batch响应的future</span></span><br><span class="line">    <span class="keyword">final</span> ProduceRequestResult produceFuture;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Header[] headers, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 检查是否有足够的缓存，存储此条消息。</span></span><br><span class="line">        <span class="comment">// 如果没有，则返回null</span></span><br><span class="line">        <span class="keyword">if</span> (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 将消息添加到MemoryRecords构造器里</span></span><br><span class="line">            Long checksum = <span class="keyword">this</span>.recordsBuilder.append(timestamp, key, value, headers);</span><br><span class="line">            <span class="comment">// 生成此条消息响应数据的future</span></span><br><span class="line">            <span class="comment">// 注意到使用了this.recordCount属性，来表示此条消息在batch中的位置</span></span><br><span class="line">            FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount, timestamp, checksum, key == <span class="keyword">null</span> ? -<span class="number">1</span> : key.length, value == <span class="keyword">null</span> ? -<span class="number">1</span> : value.length);</span><br><span class="line">            <span class="comment">// 将回调函数和future添加到thunks队列</span></span><br><span class="line">            thunks.add(<span class="keyword">new</span> Thunk(callback, future));</span><br><span class="line">            <span class="comment">// 更新消息数目</span></span><br><span class="line">            <span class="keyword">this</span>.recordCount++;</span><br><span class="line">            <span class="keyword">return</span> future;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> MemoryRecords <span class="title">records</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// tryAppend方法会将消息添加到recordsBuilder，这里调用build方法即可生成MemoryRecords</span></span><br><span class="line">        <span class="keyword">return</span> recordsBuilder.build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面添加消息的时候，ProducerBatch将回调函数和响应结果都保存在了thunks列表里。Sender线程在接收完响应后，会调用ProducerBatch的done方法，负责执行回调函数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerBatch</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">done</span><span class="params">(<span class="keyword">long</span> baseOffset, <span class="keyword">long</span> logAppendTime, RuntimeException exception)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 更新状态</span></span><br><span class="line">        <span class="keyword">final</span> FinalState finalState;</span><br><span class="line">        <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">            finalState = FinalState.SUCCEEDED;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            finalState = FinalState.FAILED;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 执行回调函数</span></span><br><span class="line">        completeFutureAndFireCallbacks(baseOffset, logAppendTime, exception);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;  </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// baseOffset为该batch 在 Kafka topic partition 中的位置</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">completeFutureAndFireCallbacks</span><span class="params">(<span class="keyword">long</span> baseOffset, <span class="keyword">long</span> logAppendTime, RuntimeException exception)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 通过set方法设置batch的响应数据</span></span><br><span class="line">        produceFuture.set(baseOffset, logAppendTime, exception);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行每个消息的回调函数</span></span><br><span class="line">        <span class="keyword">for</span> (Thunk thunk : thunks) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">// 获取消息的响应数据，并执行回调函数</span></span><br><span class="line">                    RecordMetadata metadata = thunk.future.value();</span><br><span class="line">                    <span class="keyword">if</span> (thunk.callback != <span class="keyword">null</span>)</span><br><span class="line">                        <span class="comment">// 注意这里第二个参数表示异常。如果为null，则表示请求成功</span></span><br><span class="line">                        thunk.callback.onCompletion(metadata, <span class="keyword">null</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// 注意到这儿，如果此次请求异常，只有设置消息的回调函数，才能知道</span></span><br><span class="line">                    <span class="comment">// 第二次参数表示异常实例</span></span><br><span class="line">                    <span class="keyword">if</span> (thunk.callback != <span class="keyword">null</span>)</span><br><span class="line">                        thunk.callback.onCompletion(<span class="keyword">null</span>, exception);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                log.error(<span class="string">"Error executing user-provided callback on message for topic-partition '&#123;&#125;'"</span>, topicPartition, e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 表示future已完成</span></span><br><span class="line">        produceFuture.done();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="RecordAccumulator-添加消息"><a href="#RecordAccumulator-添加消息" class="headerlink" title="RecordAccumulator 添加消息"></a>RecordAccumulator 添加消息</h3><p>RecordAccumulator的append方法，负责添加消息。append方法主要是负责管理ProducerBatch队列，当ProducerBatch数据已满，就会新建ProducerBatch。真正的添加消息是在tryAppend方法里。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">RecordAccumulator</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 消息集合，Key为分区，Value为该分区对应的batch队列</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; batches;</span><br><span class="line">    <span class="comment">// ProducerBatch可以保存数据的最小长度</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> batchSize;</span><br><span class="line">    <span class="comment">// 缓存池</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BufferPool free;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">byte</span>[] key,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">byte</span>[] value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Header[] headers,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Callback callback,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        </span><br><span class="line">        ByteBuffer buffer = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (headers == <span class="keyword">null</span>) headers = Record.EMPTY_HEADERS;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 获取该分区的batch队列，如果没有就创建</span></span><br><span class="line">            Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">            <span class="comment">// 这里使用了锁，保证线程竞争</span></span><br><span class="line">            <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">                <span class="keyword">if</span> (closed)</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line">                <span class="comment">// 调用tryAppend方法添加，如果返回null，则表示当前ProducerBatch空间已满</span></span><br><span class="line">                RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">                <span class="comment">// 表示添加成功</span></span><br><span class="line">                <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)</span><br><span class="line">                    <span class="keyword">return</span> appendResult;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">byte</span> maxUsableMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">            <span class="comment">// 确定batch的大小，比较当前消息的长度和指定最小的长度</span></span><br><span class="line">            <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">            <span class="comment">// 从缓冲池中申请内存</span></span><br><span class="line">            buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">            <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">                <span class="keyword">if</span> (closed)</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line">                <span class="comment">// 因为在申请内存的时候，Sender线程有可能刚好提取了消息，所以这里再次尝试调用tryAppend</span></span><br><span class="line">                <span class="comment">// 或者别的线程已经在这个时候，创建完了新的ProducerBatch</span></span><br><span class="line">                RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">                <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">return</span> appendResult;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 生成MemoryRecords构造器，它使用的缓存就是刚刚申请</span></span><br><span class="line">                MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">                <span class="comment">// 新建ProducerBatch</span></span><br><span class="line">                ProducerBatch batch = <span class="keyword">new</span> ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">                <span class="comment">// 调用新建的ProducerBatch的tryAppend方法添加数据</span></span><br><span class="line">                FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line">                <span class="comment">// 将新建的ProducerBatch，添加到队列里</span></span><br><span class="line">                dq.addLast(batch);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 因为这个buffer已经被新的ProducerBatch所使用，</span></span><br><span class="line">                <span class="comment">// 所以这里将其设置null，防止被释放</span></span><br><span class="line">                buffer = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="keyword">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 如果申请的buffer没有用到，这里需要将其释放掉</span></span><br><span class="line">            <span class="keyword">if</span> (buffer != <span class="keyword">null</span>)</span><br><span class="line">                free.deallocate(buffer);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 负责将消息添加到，batch队列中的最后一个</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> RecordAppendResult <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Header[] headers, Callback callback, Deque&lt;ProducerBatch&gt; deque)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 取出最后的ProducerBatch</span></span><br><span class="line">        ProducerBatch last = deque.peekLast();</span><br><span class="line">        <span class="keyword">if</span> (last != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 调用batch的tryAppend添加</span></span><br><span class="line">            FutureRecordMetadata future = last.tryAppend(timestamp, key, value, headers, callback, time.milliseconds());</span><br><span class="line">            <span class="comment">// 如果返回null，表示当前batch的空间已满</span></span><br><span class="line">            <span class="keyword">if</span> (future == <span class="keyword">null</span>)</span><br><span class="line">                <span class="comment">// 关闭当前batch的添加</span></span><br><span class="line">                last.closeForRecordAppends();</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="comment">// 返回RecordAppendResult</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, deque.size() &gt; <span class="number">1</span> || last.isFull(), <span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="RecordAccumulator-消费消息"><a href="#RecordAccumulator-消费消息" class="headerlink" title="RecordAccumulator 消费消息"></a>RecordAccumulator 消费消息</h3><p>Sender作为消息的消费者，它涉及到RecordAccumulator的两个方法：</p>
<ol>
<li><p>RecordAccumulator的ready方法负责，来查看哪些节点的请求需要发送。</p>
</li>
<li><p>RecordAccumulator的drain方法负责，从队列中提取消息。目前这里先不考虑事务，代码简化如下</p>
</li>
</ol>
<p>首先看ready方法，它会根据好几个方面，来判断是否应该发送请求。只要满足下面一种，就会认为需要发送</p>
<ul>
<li>内存紧张时，因为RecordAccumulator会一直保存消息，占用内存，一直到消息发送完成才会释放</li>
<li>消息堆积一直没有发送，堆积时间超过了指定值</li>
<li>消息重试的时间间隔，已经过去</li>
<li>该batch存储消息的空间已满，需要立即发送</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">RecordAccumulator</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 消息集合，Key为分区，Value为该分区对应的batch队列</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; batches;    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> ReadyCheckResult <span class="title">ready</span><span class="params">(Cluster cluster, <span class="keyword">long</span> nowMs)</span> </span>&#123;</span><br><span class="line">        Set&lt;Node&gt; readyNodes = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">long</span> nextReadyCheckDelayMs = Long.MAX_VALUE;</span><br><span class="line">        Set&lt;String&gt; unknownLeaderTopics = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 查看缓冲池是否资源紧张</span></span><br><span class="line">        <span class="keyword">boolean</span> exhausted = <span class="keyword">this</span>.free.queued() &gt; <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 遍历batch</span></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; entry : <span class="keyword">this</span>.batches.entrySet()) &#123;</span><br><span class="line">            <span class="comment">// 获取topic partition 和 消息队列</span></span><br><span class="line">            TopicPartition part = entry.getKey();</span><br><span class="line">            Deque&lt;ProducerBatch&gt; deque = entry.getValue();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 查看topic partition的 leader副本所在的节点，因为只有leader副本才能处理写请求</span></span><br><span class="line">            Node leader = cluster.leaderFor(part);</span><br><span class="line">            <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">                <span class="keyword">if</span> (leader == <span class="keyword">null</span> &amp;&amp; !deque.isEmpty()) &#123;</span><br><span class="line">                    unknownLeaderTopics.add(part.topic());</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!readyNodes.contains(leader) &amp;&amp; !muted.contains(part)) &#123;</span><br><span class="line">                    ProducerBatch batch = deque.peekFirst();</span><br><span class="line">                    <span class="keyword">if</span> (batch != <span class="keyword">null</span>) &#123; </span><br><span class="line">                        <span class="keyword">long</span> waitedTimeMs = batch.waitedTimeMs(nowMs);</span><br><span class="line">                        <span class="comment">// 检查是否在重试时间内</span></span><br><span class="line">                        <span class="keyword">boolean</span> backingOff = batch.attempts() &gt; <span class="number">0</span> &amp;&amp; waitedTimeMs &lt; retryBackoffMs;</span><br><span class="line">                        <span class="comment">// 计算batch停留的最大时间， </span></span><br><span class="line">                        <span class="comment">// 当batch的空间一直没有写满，它允许停留的最大时间不能超过 lingerMs</span></span><br><span class="line">                        <span class="comment">// 当batch在重试期间内，重试间隔必须大于 retryBackoffMs</span></span><br><span class="line">                        <span class="keyword">long</span> timeToWaitMs = backingOff ? retryBackoffMs : lingerMs;</span><br><span class="line">                        <span class="comment">// 该topic partition是有有已经完成的batch，</span></span><br><span class="line">                        <span class="comment">// 如果batch的数目大于1，说明第一个batch肯定已经完成了，才会新建第二个batch</span></span><br><span class="line">                        <span class="comment">// 如果只有一个batch，那么查看这个batch是否已经完成</span></span><br><span class="line">                        <span class="keyword">boolean</span> full = deque.size() &gt; <span class="number">1</span> || batch.isFull();</span><br><span class="line">                        <span class="comment">// batch停留的时间超过最大时间</span></span><br><span class="line">                        <span class="keyword">boolean</span> expired = waitedTimeMs &gt;= timeToWaitMs;</span><br><span class="line">                        <span class="comment">// 满足上述条件的一种，则表示允许发送</span></span><br><span class="line">                        <span class="keyword">boolean</span> sendable = full || expired || exhausted || closed || flushInProgress();</span><br><span class="line">                        <span class="keyword">if</span> (sendable &amp;&amp; !backingOff) &#123;</span><br><span class="line">                            <span class="comment">// 添加到readyNodes列表</span></span><br><span class="line">                            readyNodes.add(leader);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="keyword">long</span> timeLeftMs = Math.max(timeToWaitMs - waitedTimeMs, <span class="number">0</span>);</span><br><span class="line">                            nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeaderTopics);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来看drain方法，如何提取消息的。它会找到节点的所有topic partition，然后从对应的ProducerBatch队列中提取。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// nodes参数，表示限制请求是这些节点</span></span><br><span class="line"><span class="keyword">public</span> Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; drain(Cluster cluster, Set&lt;Node&gt; nodes, <span class="keyword">int</span> maxSize, <span class="keyword">long</span> now) &#123;</span><br><span class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Node node : nodes) &#123;</span><br><span class="line">        <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 获取该节点有哪些分区</span></span><br><span class="line">        List&lt;PartitionInfo&gt; parts = cluster.partitionsForNode(node.id());</span><br><span class="line">        List&lt;ProducerBatch&gt; ready = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="comment">// drainIndex是RecordAccumulator类的一个属性，</span></span><br><span class="line">        <span class="comment">// 通过它可以按照顺序遍历，而不必每次都是从第一个位置开始</span></span><br><span class="line">        <span class="keyword">int</span> start = drainIndex = drainIndex % parts.size();</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            PartitionInfo part = parts.get(drainIndex);</span><br><span class="line">            TopicPartition tp = <span class="keyword">new</span> TopicPartition(part.topic(), part.partition());</span><br><span class="line">            <span class="comment">// 当启动消息发送的幂等性，需要要求batch发送完成后，才能继续发送新的batch</span></span><br><span class="line">            <span class="keyword">if</span> (!isMuted(tp, now)) &#123;</span><br><span class="line">                <span class="comment">// 获取topic partition的消息队列</span></span><br><span class="line">                Deque&lt;ProducerBatch&gt; deque = getDeque(tp);</span><br><span class="line">                <span class="keyword">if</span> (deque != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">                        ProducerBatch first = deque.peekFirst();</span><br><span class="line">                        <span class="keyword">if</span> (first != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            <span class="comment">// 检查是否，消息发送失败正在重试，因为重试有时间间隔要求的</span></span><br><span class="line">                            <span class="keyword">boolean</span> backoff = first.attempts() &gt; <span class="number">0</span> &amp;&amp; first.waitedTimeMs(now) &lt; retryBackoffMs;</span><br><span class="line">                            <span class="keyword">if</span> (!backoff) &#123;</span><br><span class="line">                                <span class="comment">// 检查batch是否超过了指定的最大值</span></span><br><span class="line">                                <span class="keyword">if</span> (size + first.estimatedSizeInBytes() &gt; maxSize &amp;&amp; !ready.isEmpty()) &#123;</span><br><span class="line">                                    <span class="keyword">break</span>;</span><br><span class="line">                                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                    <span class="comment">// 取出batch，添加到ready列表里</span></span><br><span class="line">                                    ProducerIdAndEpoch producerIdAndEpoch = <span class="keyword">null</span>;</span><br><span class="line">                                    <span class="keyword">boolean</span> isTransactional = <span class="keyword">false</span>;</span><br><span class="line">                                    ProducerBatch batch = deque.pollFirst();</span><br><span class="line">                                    batch.close();</span><br><span class="line">                                    size += batch.records().sizeInBytes();</span><br><span class="line">                                    ready.add(batch);</span><br><span class="line">                                    <span class="comment">// 设置batch的drain的时间点</span></span><br><span class="line">                                    batch.drained(now);</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 更新drainIndex，指向下一个</span></span><br><span class="line">            <span class="keyword">this</span>.drainIndex = (<span class="keyword">this</span>.drainIndex + <span class="number">1</span>) % parts.size();</span><br><span class="line">        &#125; <span class="keyword">while</span> (start != drainIndex);</span><br><span class="line">        <span class="comment">// 将这个节点的请求，添加到batches集合</span></span><br><span class="line">        batches.put(node.id(), ready);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batches;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="消息发送者-Sender"><a href="#消息发送者-Sender" class="headerlink" title="消息发送者 Sender"></a>消息发送者 Sender</h2><p>Sender实现了Runnable接口，它运行在一个单独的线程里。它会循环的从RecordAccumulator获取消息，并且通过NetworkClient发送消息。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sender</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaClient client;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RecordAccumulator accumulator;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Metadata metadata;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (running) &#123;</span><br><span class="line">            run(time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">            ...... <span class="comment">// 这里暂时不讨论事务</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 调用sendProducerData发送消息</span></span><br><span class="line">        <span class="keyword">long</span> pollTimeout = sendProducerData(now);</span><br><span class="line">        <span class="comment">// 调用client的poll方法发送消息和处理响应</span></span><br><span class="line">        client.poll(pollTimeout, now);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">sendProducerData</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 获取元数据</span></span><br><span class="line">        Cluster cluster = metadata.fetch();</span><br><span class="line">        <span class="comment">// 从accumulator获取，需要发送消息给哪些节点</span></span><br><span class="line">        RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line">        <span class="comment">// 如果存在leader未知的情况，请求更新元数据</span></span><br><span class="line">        <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123; </span><br><span class="line">            <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</span><br><span class="line">                <span class="keyword">this</span>.metadata.add(topic);</span><br><span class="line">            <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 从accumulator获取消息</span></span><br><span class="line">        Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="keyword">this</span>.maxRequestSize, now);</span><br><span class="line">        <span class="comment">// 当请求数目过多，或者网络原因，导致有些batch很久都未能发送出去</span></span><br><span class="line">        <span class="comment">// 这里会认为batch失败，不再重新发送</span></span><br><span class="line">        List&lt;ProducerBatch&gt; expiredBatches = <span class="keyword">this</span>.accumulator.expiredBatches(<span class="keyword">this</span>.requestTimeout, now);</span><br><span class="line">        <span class="keyword">for</span> (ProducerBatch expiredBatch : expiredBatches) &#123;</span><br><span class="line">            <span class="comment">// 调用failBatch处理过期的batch</span></span><br><span class="line">            failBatch(expiredBatch, -<span class="number">1</span>, NO_TIMESTAMP, expiredBatch.timeoutException(), <span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 调用sendProduceRequests发送请求</span></span><br><span class="line">        sendProduceRequests(batches, now);</span><br><span class="line">    &#125;               </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>sendProduceRequests方法会为每个节点，构造请求，并且调用NetworkClient发送出去。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;ProducerBatch&gt; batches)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 存储着要发送的消息，会被用在构建ProduceRequest请求</span></span><br><span class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line">    <span class="comment">// 保存着发送的batch，会被用在回调函数里，处理响应</span></span><br><span class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, ProducerBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line">    <span class="comment">// 遍历batch</span></span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        TopicPartition tp = batch.topicPartition;</span><br><span class="line">        <span class="comment">// 生成 MemoryRecords</span></span><br><span class="line">        MemoryRecords records = batch.records();</span><br><span class="line">        <span class="comment">// 将records保存到produceRecordsByPartition集合</span></span><br><span class="line">        produceRecordsByPartition.put(tp, records);</span><br><span class="line">        <span class="comment">// 将batch保存在recordsByPartition集合里</span></span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 实例ProduceRequest请求构造器</span></span><br><span class="line">    ProduceRequest.Builder requestBuilder = ProduceRequest.Builder.forMagic(minUsedMagic, acks, timeout, produceRecordsByPartition, transactionalId);</span><br><span class="line">    <span class="comment">// 生成回调函数，本质调用了handleProduceResponse方法</span></span><br><span class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</span><br><span class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    String nodeId = Integer.toString(destination);</span><br><span class="line">    <span class="comment">// 生成请求</span></span><br><span class="line">    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>, callback);</span><br><span class="line">    <span class="comment">// 调用NetworkClient发送请求</span></span><br><span class="line">    client.send(clientRequest, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意到上面的回调函数，它会处理响应。它会解析请求，然后执行每个batch的回调函数。而每个batch会为每个它的每条消息，生成响应，并且执行每条消息的回调。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleProduceResponse</span><span class="params">(ClientResponse response, Map&lt;TopicPartition, ProducerBatch&gt; batches, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 解析响应，获取ProduceResponse</span></span><br><span class="line">    ProduceResponse produceResponse = (ProduceResponse) response.responseBody();</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, ProduceResponse.PartitionResponse&gt; entry : produceResponse.responses().entrySet()) &#123;</span><br><span class="line">        TopicPartition tp = entry.getKey();</span><br><span class="line">        ProduceResponse.PartitionResponse partResp = entry.getValue();</span><br><span class="line">        ProducerBatch batch = batches.get(tp);</span><br><span class="line">        <span class="comment">// completeBatch负责执行回调，最终是调用了completeBatch方法</span></span><br><span class="line">        completeBatch(batch, partResp, correlationId, now);</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">completeBatch</span><span class="params">(ProducerBatch batch, ProduceResponse.PartitionResponse response)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 调用batch的done方法，触发batch回调</span></span><br><span class="line">    <span class="keyword">if</span> (batch.done(response.baseOffset, response.logAppendTime, <span class="keyword">null</span>))</span><br><span class="line">        <span class="keyword">this</span>.accumulator.deallocate(batch);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/kafka-producer/" rel="tag"># kafka, producer</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/08/kafka-metadata/" rel="next" title="Kafka 客户端元数据">
                <i class="fa fa-chevron-left"></i> Kafka 客户端元数据
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/12/kafka-consumer-network-client/" rel="prev" title="Kafka ConsumerNetworkClient 原理">
                Kafka ConsumerNetworkClient 原理 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">zhmin</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">83</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">72</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zhmin" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka-Producer-原理"><span class="nav-number">1.</span> <span class="nav-text">Kafka Producer 原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#消息生成者-KafkaProducer"><span class="nav-number">1.1.</span> <span class="nav-text">消息生成者 KafkaProducer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#消息缓冲区-RecordAccumulator"><span class="nav-number">1.2.</span> <span class="nav-text">消息缓冲区 RecordAccumulator</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ProducerBatch-原理"><span class="nav-number">1.2.1.</span> <span class="nav-text">ProducerBatch 原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RecordAccumulator-添加消息"><span class="nav-number">1.2.2.</span> <span class="nav-text">RecordAccumulator 添加消息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RecordAccumulator-消费消息"><span class="nav-number">1.2.3.</span> <span class="nav-text">RecordAccumulator 消费消息</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#消息发送者-Sender"><span class="nav-number">1.3.</span> <span class="nav-text">消息发送者 Sender</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhmin</span>

  
</div>











  <script src="https://unpkg.com/mermaid@8/dist/mermaid.min.js"></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"startOnload":true,"theme":"forest"});
    }
  </script>



<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">
    访问量<span id="busuanzi_value_site_pv"></span>
</span>
<span class="post-meta-divider">|</span>
<span id="busuanzi_container_site_uv">
  访客数<span id="busuanzi_value_site_uv"></span>
</span>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'iYiPQlDR2X2zg2QIql2UEe2o-gzGzoHsz',
        appKey: 'EW8G4sftwX1pef1zS9EsOeKE',
        placeholder: 'comment here',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("iYiPQlDR2X2zg2QIql2UEe2o-gzGzoHsz", "EW8G4sftwX1pef1zS9EsOeKE");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  

</body>
</html>
